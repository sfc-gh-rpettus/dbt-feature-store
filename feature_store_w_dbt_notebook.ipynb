{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0081d1c-a5a4-4e6a-8c0d-1c82a31388b6",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "# Snowflake Featue Store with dbt Feature Pipelines\n\nThis notebook will walk through an example of using Snowflake's feature store in combination with dbt for managing feature pipelines. We'll see how feature tables can be created in dbt and then used as shareable features in Snowflake's feature store. \n\nTo follow along, you will need a dbt Cloud account."
  },
  {
   "cell_type": "markdown",
   "id": "7ea70d33-8d8d-41d3-b420-c8133e318085",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "## Project Setup\n\nIn this section we will set up the necessary schemas and we'll use the ExampleHelper in ```snowflake.ml.feature_store ``` to create a dataset to work with."
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Import python packages\nfrom snowflake.ml.feature_store.examples.example_helper import ExampleHelper\nfrom snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5661efb3-5f99-40b3-adff-e818d93f4298",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "# create some python variables that we will use in the project representing your named database, and schema\n# You can create a separate schema for the feature store and its objects\nfs_db = 'DBT_FS' # database for your project\nfs_data_schema = 'DBT_FS_DBT_FS' # plug in where your data lands based on the dbt model outputs\nfs_schema = 'FS_SCHEMA' # schema where the feature store will live",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "collapsed": false
   },
   "source": "-- set context and create schemas. \n-- Note this already assumes you have created the database where your notebook is running currently.\n\nuse role sysadmin;\nuse database dbt_fs;\n\n-- create a raw schema where we will dump the data\ncreate schema if not exists raw;\n\n-- create a schema specific for the feature store \ncreate schema if not exists fs_schema;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f4374ee1-d941-4409-9588-9aee92cc36e5",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false
   },
   "outputs": [],
   "source": "# use the ExampleHelper to get a dataset and write it to the below database and schema\nhelper = ExampleHelper(session, 'dbt_fs', 'raw')\nsource_table = helper.load_source_data('fraud_transactions')[0]\nsession.table(source_table).limit(5).to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7261a254-9ca4-456f-8882-f057f7e26466",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- date represents April through August 31 2019, so create a version through July for initial prep\nCREATE OR REPLACE TABLE dbt_fs.raw.transactions AS (\nSELECT *\nFROM dbt_fs.raw.fraud_transactions\nWHERE TX_DATETIME < '2019-08-01'\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e7e7882f-d8cc-4acc-bb20-14c61b993357",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "## DBT Cloud\n\nNow we are going to need to jump over to dbt Cloud, which you will need an account. You can sign up for a trial here. Once you do this, you will need to clone this [repo](https://github.com/sfc-gh-rpettus/dbt-feature-store) and run ```dbt build```. \n\nOnce you have successfully run the models in dbt you can jump back to the notebook to begin setting up the feature store."
  },
  {
   "cell_type": "code",
   "id": "086603b1-c89c-4872-a0a8-3c1cc3c10d87",
   "metadata": {
    "language": "python",
    "name": "cell19",
    "collapsed": false
   },
   "outputs": [],
   "source": "# look at the \nsession.sql(f\"SELECT * FROM {fs_db}.{fs_data_schema}.ft_customer_transactions\").limit(10)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f75662d1-65af-4585-8876-348c7ef6d0f7",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": "## Feature Store Setup\n\nIn this section we will:\n1. Create a feature store in Snowflake\n2. Register entities\n3. Create feature views that reference our feature tables created in dbt\n4. Generate a training dataset using a feature view\n5. Demonstrate how the feature view can be used in an inference dataset"
  },
  {
   "cell_type": "code",
   "id": "5bdbd75d-c49e-4cf1-936f-821f9b07110b",
   "metadata": {
    "language": "python",
    "name": "cell20",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.ml.feature_store import (\n    FeatureStore,\n    FeatureView,\n    Entity,\n    CreationMode\n)\n\nfs = FeatureStore(\n    session=session, \n    database=fs_db, \n    name=fs_schema, \n    default_warehouse='WH_DBT',\n    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b134dc7b-9763-4b92-8b56-3fa886f5aafd",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "collapsed": false
   },
   "outputs": [],
   "source": "customer = Entity(name=\"CUSTOMER\", join_keys=[\"CUSTOMER_ID\"])\ntransaction = Entity(name=\"TRANSACTION\", join_keys=[\"TRANSACTION_ID\"])\nfs.register_entity(customer)\nfs.register_entity(transaction)\nfs.list_entities().show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4847d05a-3622-451a-92fc-298faaedbf3f",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "collapsed": false
   },
   "outputs": [],
   "source": "# now create a dataframe from our feature table produced in dbt\ncustomers_transactions_df = session.sql(f\"\"\"\n    SELECT \n        CUSTOMER_ID,\n        TX_DATETIME,\n        TX_AMOUNT_1D,\n        TX_AMOUNT_7D,\n        TX_AMOUNT_30D,\n        TX_AMOUNT_AVG_1D,\n        TX_AMOUNT_AVG_7D,\n        TX_AMOUNT_AVG_30D,\n        TX_CNT_1D,\n        TX_CNT_7D,\n        TX_CNT_30D     \n    FROM {fs_db}.{fs_data_schema}.ft_customer_transactions\n    \"\"\")\n\n# now create a feature view on top of these features\ncustomer_transactions_fv = FeatureView(\n    name=\"customer_transactions_fv\", \n    entities=[customer],\n    feature_df=customers_transactions_df,\n    timestamp_col=\"TX_DATETIME\",\n    refresh_freq=None,\n    desc=\"Customer transaction features with window aggregates\")\n\n# now register the feature view for use beyond the session\ncustomer_transactions_fv = fs.register_feature_view(\n    feature_view=customer_transactions_fv,\n    version=\"1\",\n    #overwrite=True,\n    block=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76dab6ca-f2e6-4188-b059-6614d965bfbb",
   "metadata": {
    "language": "python",
    "name": "cell22",
    "collapsed": false
   },
   "outputs": [],
   "source": "# now create a dataframe from our feature table produced in dbt\ntransaction_times_df = session.sql(f\"\"\"\n    SELECT \n        TRANSACTION_ID,\n        TX_DATETIME,\n        TX_DURING_WEEKEND,\n        TX_DURING_NIGHT\n    FROM {fs_db}.{fs_data_schema}.ft_transaction_times\n    \"\"\")\n\n# now create a feature view on top of these features\ntransaction_times_fv = FeatureView(\n    name=\"transaction_times_fv\", \n    entities=[transaction],\n    feature_df=transaction_times_df,\n    timestamp_col=\"TX_DATETIME\",\n    refresh_freq=None,\n    desc=\"classification of date times for nights weekends\")\n\n# now register the feature view for use beyond the session\ntransaction_times_fv = fs.register_feature_view(\n    feature_view=transaction_times_fv,\n    version=\"1\",\n    #overwrite=True,\n    block=True)\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46627884-2643-4001-b4be-f9e671741ed0",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "collapsed": false
   },
   "outputs": [],
   "source": "fs.list_feature_views().to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cb8ca578-f39e-4565-ba60-0ae3c7f944b5",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "collapsed": false
   },
   "outputs": [],
   "source": "spine_df = session.create_dataframe(\n    [\n        ('1', '3937', \"2019-05-01 00:00\"), \n        ('2', '2', \"2019-05-01 00:00\"),\n        ('3', '927', \"2019-05-01 00:00\"),\n    ], \n    schema=[\"INSTANCE_ID\", \"CUSTOMER_ID\", \"EVENT_TIMESTAMP\"])\n\ntrain_dataset = fs.generate_dataset(\n    name= \"customers_fv\",\n    version= \"1_0\",\n    spine_df=spine_df,\n    features=[customer_transactions_fv],\n    spine_timestamp_col= \"EVENT_TIMESTAMP\",\n    spine_label_cols = []\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b28a63db-6627-49e3-b746-9d32e1bd4be6",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "collapsed": false
   },
   "outputs": [],
   "source": "training_data_df = train_dataset.read.to_snowpark_dataframe()\ntraining_data_df.limit(10)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "codeCollapsed": false,
    "collapsed": false
   },
   "source": "# now let's see how this can be used in an inference pipeline. \n# The modeling process is out of scope for this exercise.\n# But you can plug this into a model that you have deployed for your predictions.\n\ninfernce_spine = session.create_dataframe(\n    [\n        ('1', '3937', \"2019-07-01 00:00\"), \n        ('2', '2', \"2019-07-01 00:00\"),\n        ('3', '927', \"2019-07-01 00:00\"),\n    ], \n    schema=[\"INSTANCE_ID\", \"CUSTOMER_ID\", \"EVENT_TIMESTAMP\"])\n\ninference_dataset = fs.retrieve_feature_values(\n    spine_df=infernce_spine,\n    features=[customer_transactions_fv],\n    spine_timestamp_col=\"EVENT_TIMESTAMP\",\n)\n\ninference_dataset.to_pandas()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c4c1a219-8576-4857-9115-e8d836bb3ea2",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": ""
  },
  {
   "cell_type": "code",
   "id": "e1d60648-ec80-4db5-9074-5db7f3a178ba",
   "metadata": {
    "language": "sql",
    "name": "cell16",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- clean up \n-- drop schema fs_schema;",
   "execution_count": null
  }
 ]
}